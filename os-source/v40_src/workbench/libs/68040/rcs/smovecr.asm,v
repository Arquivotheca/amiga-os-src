head     0.5;
branch   ;
access   ;
symbols  ;
locks    ; strict;
comment  @* @;


0.5
date     91.07.11.09.50.00;  author mks;  state Exp;
branches ;
next     0.4;

0.4
date     91.07.08.15.48.22;  author mks;  state Exp;
branches ;
next     0.3;

0.3
date     91.07.03.10.28.00;  author mks;  state Exp;
branches ;
next     0.2;

0.2
date     91.07.02.14.39.17;  author mks;  state Exp;
branches ;
next     0.1;

0.1
date     91.06.26.09.00.03;  author mks;  state Exp;
branches ;
next     ;


desc
@68040 FPU Emulation code
@


0.5
log
@Removed all conditional code for the FMOVEM assembler bug.
HX68 V.81 is the minimum version needed to correctly assembly this code.
@
text
@*
* $Id: smovecr.asm,v 0.4 91/07/08 15:48:22 mks Exp Locker: mks $
*
* $Log:	smovecr.asm,v $
* Revision 0.4  91/07/08  15:48:22  mks
* Ok, so this is an ugly hack to work around the FMOVEM problem...
* It turns out that the assembler just did not notice that the register was
* an FPU register unless there was a register list.  So...  we make all FMOVEMs
* that have only one FPU register, show it twice.  For example:
* fmovem.x  fp0,(a0)            This would become:
* fmovem.x  fp0/fp0,(a0)
*
* This fools the assembler into doing the right thing.  It is all within
* conditional assembly so that when a fixed assembler comes, it can easily
* be tested and the kludge removed.
*
* Revision 0.3  91/07/03  10:28:00  mks
* First pass at doing branch optimizations
*
* Revision 0.2  91/07/02  14:39:17  mks
* Added conditional kludges for FMOVEM bug fix
*
* Revision 0.1  91/06/26  09:00:03  mks
* Initial check in...
*
*

	include	"assembly_options.i"

*
*	smovecr.sa 3.1 12/10/90
*
*	The entry point sMOVECR returns the constant at the
*	offset given in the instruction field.
*
*	Input: An offset in the instruction word.
*
*	Output:	The constant rounded to the user's rounding
*		mode unchecked for overflow.
*
*	Modified: fp0.
*
*
*		Copyright (C) Motorola, Inc. 1990
*			All Rights Reserved
*
*	THIS IS UNPUBLISHED PROPRIETARY SOURCE CODE OF MOTOROLA
*	The copyright notice above does not evidence any
*	actual or intended publication of such source code.

SMOVECR	IDNT	2,1 Motorola 040 Floating Point Software Package

	section 8

	include "fpsp.i"

	xref	nrm_set
	xref	round
	xref	PIRN
	xref	PIRZRM
	xref	PIRP
	xref	SMALRN
	xref	SMALRZRM
	xref	SMALRP
	xref	BIGRN
	xref	BIGRZRM
	xref	BIGRP

FZERO	dc.l	00000000
*
*	FMOVECR
*
	xdef	smovcr
smovcr:
	bfextu	CMDREG1B(a6){9:7},d0 ;get offset
	bfextu	USER_FPCR(a6){26:2},d1 ;get rmode
*
* check range of offset
*
	tst.b	d0		;if zero, offset is to pi
	beq.b	PI_TBL		;it is pi
	cmpi.b	#$0a,d0		;check range $01 - $0a
	ble.b	Z_VAL		;if in this range, return zero
	cmpi.b	#$0e,d0		;check range $0b - $0e
	ble.b	SM_TBL		;valid constants in this range
	cmpi.b	#$2f,d0		;check range $10 - $2f
	ble.b	Z_VAL		;if in this range, return zero
	cmpi.b	#$3f,d0		;check range $30 - $3f
	ble.s  	BG_TBL		;valid constants in this range
Z_VAL:
	fmove.s	FZERO,fp0
	rts
PI_TBL:
	tst.b	d1		;offset is zero, check for rmode
	beq.b	PI_RN		;if zero, rn mode
	cmpi.b	#$3,d1		;check for rp
	beq.b	PI_RP		;if 3, rp mode
PI_RZRM:
	lea.l	PIRZRM,a0	;rmode is rz or rm, load PIRZRM in a0
	bra	set_finx
PI_RN:
	lea.l	PIRN,a0		;rmode is rn, load PIRN in a0
	bra	set_finx
PI_RP:
	lea.l	PIRP,a0		;rmode is rp, load PIRP in a0
	bra	set_finx
SM_TBL:
	subi.l	#$b,d0		;make offset in 0 - 4 range
	tst.b	d1		;check for rmode
	beq.b	SM_RN		;if zero, rn mode
	cmpi.b	#$3,d1		;check for rp
	beq.b	SM_RP		;if 3, rp mode
SM_RZRM:
	lea.l	SMALRZRM,a0	;rmode is rz or rm, load SMRZRM in a0
	cmpi.b	#$2,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 2, it is inexact
	bra.s	no_finx		;if 3, it is exact
SM_RN:
	lea.l	SMALRN,a0	;rmode is rn, load SMRN in a0
	cmpi.b	#$2,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 2, it is inexact
	bra.s	no_finx		;if 3, it is exact
SM_RP:
	lea.l	SMALRP,a0	;rmode is rp, load SMRP in a0
	cmpi.b	#$2,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 2, it is inexact
	bra.s	no_finx		;if 3, it is exact
BG_TBL:
	subi.l	#$30,d0		;make offset in 0 - f range
	tst.b	d1		;check for rmode
	beq.b	BG_RN		;if zero, rn mode
	cmpi.b	#$3,d1		;check for rp
	beq.b	BG_RP		;if 3, rp mode
BG_RZRM:
	lea.l	BIGRZRM,a0	;rmode is rz or rm, load BGRZRM in a0
	cmpi.b	#$1,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 1, it is inexact
	cmpi.b	#$7,d0		;second check
	ble.s	no_finx		;if 0 - 7, it is exact
	bra.s	set_finx	;if 8 - f, it is inexact
BG_RN:
	lea.l	BIGRN,a0	;rmode is rn, load BGRN in a0
	cmpi.b	#$1,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 1, it is inexact
	cmpi.b	#$7,d0		;second check
	ble.s	no_finx		;if 0 - 7, it is exact
	bra.s	set_finx	;if 8 - f, it is inexact
BG_RP:
	lea.l	BIGRP,a0	;rmode is rp, load SMRP in a0
	cmpi.b	#$1,d0		;check if result is inex
	ble.s	set_finx	;if 0 - 1, it is inexact
	cmpi.b	#$7,d0		;second check
	ble.s	no_finx		;if 0 - 7, it is exact
*	bra.s	set_finx	;if 8 - f, it is inexact
set_finx:
	or.l	#inx2a_mask,USER_FPSR(a6) ;set inex2/ainex
no_finx:
	mulu.l	#12,d0			;use offset to point into tables
	move.l	d1,L_SCR1(a6)		;load mode for round call
	bfextu	USER_FPCR(a6){24:2},d1	;get precision
	tst.l	d1			;check if extended precision
*
* Precision is extended
*
	bne.b	not_ext			;if extended, do not call round
	fmovem.x (a0,d0),fp0		;return result in fp0
	rts
*
* Precision is single or double
*
not_ext:
	swap	d1			;rnd prec in upper word of d1
	add.l	L_SCR1(a6),d1		;merge rmode in low word of d1
	move.l	(a0,d0),FP_SCR1(a6)	;load first word to temp storage
	move.l	4(a0,d0),FP_SCR1+4(a6)	;load second word
	move.l	8(a0,d0),FP_SCR1+8(a6)	;load third word
	clr.l	d0			;clear g,r,s
	lea	FP_SCR1(a6),a0
	btst.b	#sign_bit,LOCAL_EX(a0)
	sne	LOCAL_SGN(a0)		;convert to internal ext. format

	bsr	round			;go round the mantissa

	bfclr	LOCAL_SGN(a0){0:8}	;convert back to IEEE ext format
	beq.b	fin_fcr
	bset.b	#sign_bit,LOCAL_EX(a0)
fin_fcr:
	fmovem.x (a0),fp0
	rts

	end
@


0.4
log
@Ok, so this is an ugly hack to work around the FMOVEM problem...
It turns out that the assembler just did not notice that the register was
an FPU register unless there was a register list.  So...  we make all FMOVEMs
that have only one FPU register, show it twice.  For example:
fmovem.x  fp0,(a0)            This would become:
fmovem.x  fp0/fp0,(a0)

This fools the assembler into doing the right thing.  It is all within
conditional assembly so that when a fixed assembler comes, it can easily
be tested and the kludge removed.
@
text
@d2 1
a2 1
* $Id: smovecr.asm,v 0.3 91/07/03 10:28:00 mks Exp Locker: mks $
d5 12
a165 4

 ifne FMOVEM_BUG
	fmovem.x (a0,d0),fp0/fp0	;return result in fp0
 else
a166 2
 endc

a187 4

 ifne FMOVEM_BUG
	fmovem.x (a0),fp0/fp0
 else
a188 2
 endc

@


0.3
log
@First pass at doing branch optimizations
@
text
@d2 1
a2 1
* $Id: smovecr.asm,v 0.2 91/07/02 14:39:17 mks Exp Locker: mks $
d5 3
d156 1
a156 1
	dc.w		$F230,$D080,$0000
d184 1
a184 1
	dc.w		$F210,$D080
@


0.2
log
@Added conditional kludges for FMOVEM bug fix
@
text
@d2 1
a2 1
* $Id: smovecr.asm,v 0.1 91/06/26 09:00:03 mks Exp Locker: mks $
d5 3
d74 1
a74 1
	ble  	BG_TBL		;valid constants in this range
d101 2
a102 2
	ble	set_finx	;if 0 - 2, it is inexact
	bra	no_finx		;if 3, it is exact
d106 2
a107 2
	ble	set_finx	;if 0 - 2, it is inexact
	bra	no_finx		;if 3, it is exact
d111 2
a112 2
	ble	set_finx	;if 0 - 2, it is inexact
	bra	no_finx		;if 3, it is exact
d122 1
a122 1
	ble	set_finx	;if 0 - 1, it is inexact
d124 2
a125 2
	ble	no_finx		;if 0 - 7, it is exact
	bra	set_finx	;if 8 - f, it is inexact
d129 1
a129 1
	ble	set_finx	;if 0 - 1, it is inexact
d131 2
a132 2
	ble	no_finx		;if 0 - 7, it is exact
	bra	set_finx	;if 8 - f, it is inexact
d136 1
a136 1
	ble	set_finx	;if 0 - 1, it is inexact
d138 2
a139 2
	ble	no_finx		;if 0 - 7, it is exact
*	bra	set_finx	;if 8 - f, it is inexact
@


0.1
log
@Initial check in...
@
text
@d2 1
a2 1
* $Id$
d4 3
a6 1
* $Log$
d8 1
d148 4
d153 2
d176 4
d181 2
@
